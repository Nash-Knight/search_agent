{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffd90379",
   "metadata": {},
   "source": [
    "Search Agent (Qwen3-0.6B) 重构版说明\n",
    "\n",
    "目标：基于本地 Qwen3-0.6B 搭建一个最小可用的搜索 Agent Pipeline。\n",
    "\n",
    "核心流程：\n",
    "1. 用户提供初始任务 prompt。\n",
    "2. 模型逐 token 生成并检测工具调用格式。\n",
    "3. 遇到搜索工具调用 => 执行搜索 => 将搜索结果注入上下文继续生成。\n",
    "4. 不再触发工具调用且出现终止标记（<eos> / eos token） => 输出最终链接集合。\n",
    "\n",
    "Notebook 结构：\n",
    "- 配置与依赖\n",
    "- 模型加载\n",
    "- 工具与解析层 (Tool / SearchTool / ToolCallParser)\n",
    "- AgentPipeline 主循环 (流式 + 工具接入)\n",
    "- 示例运行 (单函数入口)\n",
    "- 扩展建议\n",
    "\n",
    "约定：\n",
    "- 工具调用格式候选：`<tool_call:search>查询词` / `search: 查询词` / `[SEARCH] 查询词`\n",
    "- 工具响应结束 token id（暂用推测值）：151666 (</tool_response>)\n",
    "- 本示例仅做结构演示，未包含安全过滤、重试、并行优化。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e7c5d3",
   "metadata": {},
   "source": [
    "这一部分说明所需的依赖与环境前提，提醒读者检查本地模型目录 `./Qwen3-0.6B` 并在缺包时安装 `transformers`、`huggingface_hub`、`requests`、`beautifulsoup4`。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6574d46f",
   "metadata": {},
   "source": [
    "这个单元会动态检查依赖是否安装，并导入后续流程会用到的核心库；如果缺包会抛出清晰的提示便于补齐环境。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6e7f154",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch, requests, re\n",
    "from bs4 import BeautifulSoup\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Any\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458670cb",
   "metadata": {},
   "source": [
    "下面的单元负责加载本地 Qwen3-0.6B 模型与分词器，并根据是否可用 GPU 自动选择 dtype 和 device_map。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e55922a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载模型目录: Qwen3-0.6B\n",
      "模型加载完成，当前设备: cuda:0\n",
      "模型加载完成，当前设备: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# 模型与分词器加载\n",
    "MODEL_DIR = Path(\"Qwen3-0.6B\")\n",
    "if not MODEL_DIR.exists():\n",
    "    raise FileNotFoundError(f\"模型目录不存在: {MODEL_DIR.resolve()}\")\n",
    "\n",
    "print(f\"加载模型目录: {MODEL_DIR}\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(str(MODEL_DIR), local_files_only=True)\n",
    "\n",
    "dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "load_kwargs = {\"local_files_only\": True, \"torch_dtype\": dtype}\n",
    "if torch.cuda.is_available():\n",
    "    load_kwargs[\"device_map\"] = \"auto\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(str(MODEL_DIR), **load_kwargs)\n",
    "model.eval()\n",
    "print(\"模型加载完成，当前设备:\", model.device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54a2124",
   "metadata": {},
   "source": [
    "这一段用于快速检查 tokenizer 的特殊标记，以及检索包含 \"tool\" 关键词的 token 以辅助调试工具调用格式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a72bc78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "特殊 token: {'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}\n",
      "其他特殊 token: ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']\n",
      "包含 'tool' 的 token 示例 (前 100):\n",
      "45714 /tools\n",
      "56466 Ġfunctools\n",
      "48950 (tool\n",
      "72790 -toolbar\n",
      "23154 .tools\n",
      "67870 Ġtoolbox\n",
      "65695 _toolbar\n",
      "25942 Ġtoolbar\n",
      "41331 Ġitertools\n",
      "78458 (toolbar\n",
      "39723 _tools\n",
      "60646 -tooltip\n",
      "15918 tools\n",
      "65894 Ġtoolkit\n",
      "40224 -tool\n",
      "67166 .tooltip\n",
      "75027 /tool\n",
      "24680 .toolStrip\n",
      "44646 -tools\n",
      "88265 .toolbox\n",
      "36316 ertools\n",
      "21539 tooltip\n",
      "87183 toolbox\n",
      "91234 Ġtooltips\n",
      "47416 .toolbar\n",
      "7375 Ġtools\n",
      "151666 </tool_response>\n",
      "64448 .toolStripSeparator\n",
      "21268 .tool\n",
      "37530 toolbar\n",
      "76265 _tooltip\n",
      "151657 <tool_call>\n",
      "151658 </tool_call>\n",
      "84904 .toolStripMenuItem\n",
      "5392 Ġtool\n",
      "51281 uptools\n",
      "25451 Ġtooltip\n",
      "22785 _tool\n",
      "65539 toolStrip\n",
      "63072 Ġstool\n",
      "63797 Ġsetuptools\n",
      "46902 ĠtoolStrip\n",
      "151665 <tool_response>\n",
      "66572 .toolStripButton\n",
      "89772 Ġstools\n",
      "14172 tool\n"
     ]
    }
   ],
   "source": [
    "# Tokenizer 信息检查\n",
    "print(\"特殊 token:\", tokenizer.special_tokens_map)\n",
    "print(\"其他特殊 token:\", tokenizer.additional_special_tokens)\n",
    "\n",
    "matched = []\n",
    "for token, tid in tokenizer.get_vocab().items():\n",
    "    if \"tool\" in token:\n",
    "        matched.append((tid, token))\n",
    "    if len(matched) >= 100:\n",
    "        break\n",
    "print(\"包含 'tool' 的 token 示例 (前 100):\")\n",
    "for tid, token in matched:\n",
    "    print(tid, token)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56094f88",
   "metadata": {},
   "source": [
    "后续工具实现依赖一些常量，这里集中定义工具结束 token、搜索模式、HTTP 头等基础配置，保持全局可见。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2258de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 工具与解析层：基础配置\n",
    "TOOL_END_TOKEN_ID = 151666  # 推测为 </tool_response>\n",
    "SEARCH_PATTERNS = [\n",
    "    r\"search:\\s*(.*)\",       # 兼容旧格式 \"search: query\"\n",
    "    r\"\\[TOOL_CALL\\]\\s*\\n\\s*search:\\s*(.*)\", # 兼容旧多行格式\n",
    "    r\"<tool_call:search>(.*?)$\",  # 兼容旧XML样式\n",
    "    r\"\\[SEARCH\\]\\s+(.*)$\",      # 兼容旧标签\n",
    "]\n",
    "# 主要使用 <search>...</search> 新标签；旧模式保留以便混合 prompt 测试\n",
    "HEADERS = {\"User-Agent\": \"Mozilla/5.0 (SearchAgent Prototype)\"}\n",
    "MAX_LINKS_DEFAULT = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de732ac6",
   "metadata": {},
   "source": [
    "紧接着的代码定义抽象工具基类和抓取 jina.ai 搜索结果的 `SearchTool`，并处理异常返回结构化信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2d93d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 工具实现：SearchTool\n",
    "class Tool:\n",
    "    name: str\n",
    "\n",
    "    def run(self, *args, **kwargs) -> Dict[str, Any]:\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "class SearchTool(Tool):\n",
    "    name = \"search\"\n",
    "\n",
    "    def run(self, query: str, max_links: int = MAX_LINKS_DEFAULT) -> Dict[str, Any]:\n",
    "        url = f\"https://www.jina.ai/search?q={requests.utils.quote(query)}\"\n",
    "        try:\n",
    "            resp = requests.get(url, headers=HEADERS, timeout=15)\n",
    "            resp.raise_for_status()\n",
    "        except Exception as exc:\n",
    "            return {\"query\": query, \"links\": [], \"error\": str(exc)}\n",
    "\n",
    "        soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "        links: List[str] = []\n",
    "        for anchor in soup.select(\"a[href]\"):\n",
    "            href = anchor.get(\"href\")\n",
    "            if href and href.startswith(\"http\") and \"jina.ai\" not in href:\n",
    "                links.append(href)\n",
    "            if len(links) >= max_links:\n",
    "                break\n",
    "        return {\"query\": query, \"links\": links}\n",
    "\n",
    "\n",
    "search_tool = SearchTool()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0fbac1",
   "metadata": {},
   "source": [
    "为了抽取模型输出中的工具调用，这里实现 `ToolCallParser`，兼容简单正则与预留的 JSON 包装格式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4244c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 工具调用解析器\n",
    "class ToolCallParser:\n",
    "    def find_search(self, text: str):\n",
    "        for pattern in SEARCH_PATTERNS:\n",
    "            match = re.search(pattern, text, re.IGNORECASE)\n",
    "            if match:\n",
    "                query = match.group(1).strip()\n",
    "                query = re.split(r\"</tool_response>|<eos>|\\n\", query)[0].strip()\n",
    "                if query:\n",
    "                    return query\n",
    "        return None\n",
    "\n",
    "    def find_json_tool(self, text: str):\n",
    "        # 预留 JSON 工具调用格式: <tool_call>{\"name\":\"search\", ...}</tool_call>\n",
    "        match = re.search(r\"<tool_call>\\s*(\\{.*?\\})\\s*</tool_call>\", text, re.DOTALL)\n",
    "        if not match:\n",
    "            return None\n",
    "        raw_json = match.group(1)\n",
    "        try:\n",
    "            import json\n",
    "            return json.loads(raw_json)\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "\n",
    "parser = ToolCallParser()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1259774",
   "metadata": {},
   "source": [
    "在进入主循环前，需要一个统一的对话模板封装，这样模型在没有原生 chat 模板时也能 fallback 到简单的 role:content 拼接。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0f852b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chat 模板包装（改进版）\n",
    "def apply_chat_template(messages):\n",
    "    if hasattr(tokenizer, \"apply_chat_template\"):\n",
    "        try:\n",
    "            return tokenizer.apply_chat_template(\n",
    "                messages,\n",
    "                tokenize=False,\n",
    "                add_generation_prompt=True,\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"[警告] apply_chat_template 失败: {e}, 使用 fallback 方案\")\n",
    "    \n",
    "    # Fallback: 简单的消息拼接\n",
    "    lines = []\n",
    "    for m in messages:\n",
    "        role = m['role']\n",
    "        content = m['content']\n",
    "        if role == 'system':\n",
    "            lines.append(f\"System: {content}\")\n",
    "        elif role == 'user':\n",
    "            lines.append(f\"User: {content}\")\n",
    "        elif role == 'assistant':\n",
    "            lines.append(f\"Assistant: {content}\")\n",
    "    \n",
    "    lines.append(\"Assistant:\")  # 提示模型开始生成\n",
    "    return \"\\n\\n\".join(lines)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8136e26",
   "metadata": {},
   "source": [
    "接下来的 Pipeline 单元负责逐 token 流式生成、检测工具调用、执行搜索并把结果拼回消息列表，是整个 Agent 的核心逻辑。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbdc868",
   "metadata": {},
   "source": [
    "系统提示（System Prompt）\n",
    "\n",
    "下面新增一个系统级指导信息，要求模型在需要检索时使用形如 <search>关键词</search> 的标签包围搜索词。生成过程中一旦形成闭合标签即触发搜索，将搜索结果与原始关键词回注入上下文继续回答。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "961308ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 系统提示定义（简化版 - 优先保证基础对话功能）\n",
    "GLOBAL_SYSTEM_PROMPT = (\n",
    "    \"你是一个友好的助手。\"\n",
    "    \"如果需要搜索信息,用 <search>关键词</search> 标签包围搜索词。\"\n",
    "    \"否则直接回答问题。保持回答简洁自然。\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35b1efb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AgentPipeline 定义（重构版 - 修复生成逻辑）\n",
    "@dataclass\n",
    "class GenerationResult:\n",
    "    final_text: str\n",
    "    search_queries: List[str]\n",
    "    links: List[str]\n",
    "\n",
    "\n",
    "class AgentPipeline:\n",
    "    def __init__(self, model, tokenizer, tool: Tool, parser: ToolCallParser):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.tool = tool\n",
    "        self.parser = parser\n",
    "\n",
    "    def _prepare_inputs(self, messages: List[Dict[str, str]]):\n",
    "        prompt = apply_chat_template(messages)\n",
    "        if verbose_g:\n",
    "            print(\"--- PROMPT START ---\")\n",
    "            print(prompt)\n",
    "            print(\"--- PROMPT END ---\\n\")\n",
    "        encoded = self.tokenizer([prompt], return_tensors=\"pt\")\n",
    "        return (\n",
    "            encoded[\"input_ids\"].to(self.model.device),\n",
    "            encoded[\"attention_mask\"].to(self.model.device),\n",
    "        )\n",
    "\n",
    "    def _append_message(self, messages: List[Dict[str, str]], role: str, content: str):\n",
    "        messages.append({\"role\": role, \"content\": content})\n",
    "\n",
    "    def _dedup(self, items: List[str]) -> List[str]:\n",
    "        seen = set()\n",
    "        ordered = []\n",
    "        for item in items:\n",
    "            if item not in seen:\n",
    "                seen.add(item)\n",
    "                ordered.append(item)\n",
    "        return ordered\n",
    "\n",
    "    def stream(self, messages: List[Dict[str, str]], *, max_steps: int = 96, verbose: bool = True) -> GenerationResult:\n",
    "        global verbose_g\n",
    "        verbose_g = verbose\n",
    "        \n",
    "        all_generated_tokens: List[int] = []  # 记录所有生成的token\n",
    "        collected_links: List[str] = []\n",
    "        search_queries: List[str] = []\n",
    "        \n",
    "        # 支持多轮搜索-生成\n",
    "        max_search_rounds = 3\n",
    "        for search_round in range(max_search_rounds):\n",
    "            if verbose:\n",
    "                print(f\"\\n{'='*50}\")\n",
    "                print(f\"生成轮次 {search_round + 1}/{max_search_rounds}\")\n",
    "                print(f\"{'='*50}\\n\")\n",
    "            \n",
    "            input_ids, attention_mask = self._prepare_inputs(messages)\n",
    "            generated: List[int] = []\n",
    "            cache = None\n",
    "            \n",
    "            with torch.inference_mode():\n",
    "                for step in range(max_steps):\n",
    "                    outputs = self.model(\n",
    "                        input_ids=input_ids,\n",
    "                        attention_mask=attention_mask,\n",
    "                        use_cache=True,\n",
    "                        past_key_values=cache,\n",
    "                    )\n",
    "                    logits = outputs.logits[:, -1, :]\n",
    "                    cache = outputs.past_key_values\n",
    "\n",
    "                    next_token = torch.argmax(logits, dim=-1)\n",
    "                    token_id = next_token.item()\n",
    "                    generated.append(token_id)\n",
    "\n",
    "                    # 续写输入\n",
    "                    input_ids = torch.cat([input_ids, next_token.unsqueeze(0)], dim=1)\n",
    "                    attention_mask = torch.cat([\n",
    "                        attention_mask,\n",
    "                        torch.ones_like(next_token).unsqueeze(0),\n",
    "                    ], dim=1)\n",
    "\n",
    "                    token_text = self.tokenizer.decode([token_id], skip_special_tokens=False)\n",
    "                    current_text = self.tokenizer.decode(generated, skip_special_tokens=False)\n",
    "                    \n",
    "                    if verbose:\n",
    "                        print(f\"Step {step:02d} | id={token_id:6d} | {repr(token_text)}\")\n",
    "\n",
    "                    # 终止条件: EOS token\n",
    "                    if token_id == self.tokenizer.eos_token_id:\n",
    "                        if verbose:\n",
    "                            print(\"[终止] 遇到 EOS token，本轮生成结束。\")\n",
    "                        break\n",
    "                    \n",
    "                    # 检测 <search>...</search> 标签（只在生成足够长度后检测，避免过早触发）\n",
    "                    if step > 5:  # 至少生成5个token后再检测\n",
    "                        search_match = re.search(r\"<search>(.*?)</search>\", current_text, flags=re.DOTALL)\n",
    "                        if search_match:\n",
    "                            query = search_match.group(1).strip().replace(\"\\n\", \" \")\n",
    "                            if query and query not in search_queries:\n",
    "                                if verbose:\n",
    "                                    print(f\"\\n[搜索触发] query='{query}'\")\n",
    "                                search_queries.append(query)\n",
    "                                \n",
    "                                # 执行搜索\n",
    "                                result = self.tool.run(query)\n",
    "                                links = result.get(\"links\", [])\n",
    "                                collected_links.extend(links)\n",
    "                                \n",
    "                                # 构造搜索结果反馈\n",
    "                                feedback = f\"搜索词: {query}\\n找到以下链接:\\n\"\n",
    "                                if links:\n",
    "                                    feedback += \"\\n\".join(f\"{i+1}. {link}\" for i, link in enumerate(links[:5]))\n",
    "                                else:\n",
    "                                    feedback += \"(未找到相关结果)\"\n",
    "                                feedback += \"\\n\\n请基于这些信息继续回答。\"\n",
    "                                \n",
    "                                # 保存当前生成的内容\n",
    "                                all_generated_tokens.extend(generated)\n",
    "                                \n",
    "                                # 添加消息并准备下一轮生成\n",
    "                                self._append_message(messages, \"assistant\", current_text)\n",
    "                                self._append_message(messages, \"user\", feedback)\n",
    "                                \n",
    "                                if verbose:\n",
    "                                    print(f\"[搜索完成] 找到 {len(links)} 个链接，准备下一轮生成...\")\n",
    "                                break  # 跳出当前生成循环，开始新一轮\n",
    "                \n",
    "                # 本轮生成结束，检查是否需要继续\n",
    "                if step == max_steps - 1:\n",
    "                    if verbose:\n",
    "                        print(\"[警告] 达到最大步数限制\")\n",
    "                    all_generated_tokens.extend(generated)\n",
    "                    break  # 退出多轮循环\n",
    "                \n",
    "                # 如果没有触发搜索，说明正常结束\n",
    "                search_match = re.search(r\"<search>(.*?)</search>\", current_text, flags=re.DOTALL)\n",
    "                if not search_match:\n",
    "                    all_generated_tokens.extend(generated)\n",
    "                    if verbose:\n",
    "                        print(\"[正常结束] 未检测到搜索请求，生成完成。\")\n",
    "                    break  # 正常结束，退出多轮循环\n",
    "\n",
    "        # 解码最终文本\n",
    "        final_text = self.tokenizer.decode(all_generated_tokens, skip_special_tokens=True)\n",
    "        \n",
    "        return GenerationResult(\n",
    "            final_text=final_text,\n",
    "            search_queries=search_queries,\n",
    "            links=self._dedup(collected_links),\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a519b92a",
   "metadata": {},
   "source": [
    "为了方便外部调用，下面会构造 `run_search_agent` 包装函数，复用已经初始化好的 Pipeline 并打印关键信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb5cd870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 统一入口函数（优化版）\n",
    "pipeline = AgentPipeline(model=model, tokenizer=tokenizer, tool=search_tool, parser=parser)\n",
    "\n",
    "def _clean_assistant_output(raw: str) -> str:\n",
    "    \"\"\"清理模型输出中的特殊标记\"\"\"\n",
    "    import re\n",
    "    # 移除思考标签\n",
    "    cleaned = re.sub(r'<think>.*?</think>', '', raw, flags=re.DOTALL | re.IGNORECASE)\n",
    "    # 移除搜索标签（保留内容）\n",
    "    cleaned = re.sub(r'<search>(.*?)</search>', r'\\1', cleaned, flags=re.DOTALL)\n",
    "    # 移除特殊token\n",
    "    for token in ['<|im_end|>', '<eos>', '</think>', '<|endoftext|>']:\n",
    "        cleaned = cleaned.replace(token, '')\n",
    "    # 清理多余换行\n",
    "    cleaned = re.sub(r'\\n{3,}', '\\n\\n', cleaned).strip()\n",
    "    return cleaned\n",
    "\n",
    "def run_search_agent(query: str, *, max_steps: int = 128, verbose: bool = True) -> GenerationResult:\n",
    "    \"\"\"\n",
    "    运行搜索增强的 Agent\n",
    "    \n",
    "    Args:\n",
    "        query: 用户查询\n",
    "        max_steps: 每轮生成的最大步数\n",
    "        verbose: 是否打印详细信息\n",
    "    \"\"\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": GLOBAL_SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": query},\n",
    "    ]\n",
    "    \n",
    "    result = pipeline.stream(messages, max_steps=max_steps, verbose=verbose)\n",
    "    \n",
    "    # 清理输出\n",
    "    cleaned_output = _clean_assistant_output(result.final_text)\n",
    "    \n",
    "    # 打印结果摘要\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"生成完成！\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    if result.search_queries:\n",
    "        print(f\"\\n执行了 {len(result.search_queries)} 次搜索:\")\n",
    "        for i, q in enumerate(result.search_queries, 1):\n",
    "            print(f\"  {i}. {q}\")\n",
    "    \n",
    "    if result.links:\n",
    "        print(f\"\\n找到 {len(result.links)} 个链接:\")\n",
    "        for i, link in enumerate(result.links[:8], 1):  # 只显示前8个\n",
    "            print(f\"  {i}. {link}\")\n",
    "        if len(result.links) > 8:\n",
    "            print(f\"  ... (还有 {len(result.links) - 8} 个)\")\n",
    "    \n",
    "    print(\"\\n最终回答:\")\n",
    "    print(\"-\" * 60)\n",
    "    print(cleaned_output if cleaned_output else \"(空)\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb27e7f0",
   "metadata": {},
   "source": [
    "最后的示例单元提供一个默认 prompt，方便手动触发一次搜索调用进行调试；默认注释掉实际调用以免误运行。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973d2170",
   "metadata": {},
   "source": [
    "## 测试基础对话功能\n",
    "\n",
    "在测试搜索功能之前，先确保模型能够正常进行对话。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff058712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "测试 1: 基础问候 - 'hello'\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "生成完成！\n",
      "============================================================\n",
      "\n",
      "最终回答:\n",
      "------------------------------------------------------------\n",
      "<think>好\n",
      "\n",
      "<：\n",
      "\n",
      "好的 �\n",
      "\n",
      "一个搜索\n",
      "\n",
      "好的翻译\n",
      "\n",
      "词\n",
      "\n",
      " what·\n",
      "\n",
      "请，人关键词\n",
      "关于\n",
      "你的搜索的\n",
      "\n",
      "、位...文好\n",
      "------------------------------------------------------------\n",
      "\n",
      "============================================================\n",
      "生成完成！\n",
      "============================================================\n",
      "\n",
      "最终回答:\n",
      "------------------------------------------------------------\n",
      "<think>好\n",
      "\n",
      "<：\n",
      "\n",
      "好的 �\n",
      "\n",
      "一个搜索\n",
      "\n",
      "好的翻译\n",
      "\n",
      "词\n",
      "\n",
      " what·\n",
      "\n",
      "请，人关键词\n",
      "关于\n",
      "你的搜索的\n",
      "\n",
      "、位...文好\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 测试 1: 基础问候（不需要搜索）\n",
    "print(\"=\"*60)\n",
    "print(\"测试 1: 基础问候 - 'hello'\")\n",
    "print(\"=\"*60)\n",
    "simple_result = run_search_agent(\"hello\", max_steps=50, verbose=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c86462c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "测试 2: 简单问答\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "生成完成！\n",
      "============================================================\n",
      "\n",
      "最终回答:\n",
      "------------------------------------------------------------\n",
      "：\n",
      "\n",
      "。\n",
      "搜索？文\n",
      "=\n",
      "------------------------------------------------------------\n",
      "\n",
      "============================================================\n",
      "生成完成！\n",
      "============================================================\n",
      "\n",
      "最终回答:\n",
      "------------------------------------------------------------\n",
      "：\n",
      "\n",
      "。\n",
      "搜索？文\n",
      "=\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 测试 2: 简单问答（不需要搜索）\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"测试 2: 简单问答\")\n",
    "print(\"=\"*60)\n",
    "qa_result = run_search_agent(\"1+1等于几?\", max_steps=50, verbose=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6eaaa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running Complex Query ---\n",
      "--- PROMPT START ---\n",
      "<|im_start|>system\n",
      "你是一个搜索增强助手。判断需要外部信息时，请生成 <search>关键词</search> 标签。 标签内只放原始搜索关键词，避免多句。形成 </search> 闭合后会自动检索 Jina.ai。 系统会将检索到的若干链接与原始关键词回传，你需要利用这些结果综合回答。 如果不需要搜索就直接正常回答并结束。不要虚构搜索结果。<|im_end|>\n",
      "<|im_start|>user\n",
      "给我一些近期开源中文多模态项目。\n",
      "<search>开源 中文 多模态 项目</search><|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n",
      "--- PROMPT END ---\n",
      "\n",
      "Step 00 | id=151667 | '<think>'\n",
      "Step 01 | id=198 | '\\n'\n",
      "Step 02 | id=29258 | '重'\n",
      "Step 01 | id=198 | '\\n'\n",
      "Step 02 | id=29258 | '重'\n",
      "Step 03 | id=13072 | '名'\n",
      "Step 04 | id=198 | '\\n'\n",
      "Step 03 | id=13072 | '名'\n",
      "Step 04 | id=198 | '\\n'\n",
      "Step 05 | id=59258 | '近'\n",
      "Step 06 | id=78973 | '搜索'\n",
      "Step 05 | id=59258 | '近'\n",
      "Step 06 | id=78973 | '搜索'\n",
      "Step 07 | id=5373 | '、'\n",
      "Step 08 | id=198 | '\\n'\n",
      "Step 07 | id=5373 | '、'\n",
      "Step 08 | id=198 | '\\n'\n",
      "Step 09 | id=198 | '\\n'\n",
      "Step 10 | id=198 | '\\n'\n",
      "Step 09 | id=198 | '\\n'\n",
      "Step 10 | id=198 | '\\n'\n",
      "Step 11 | id=198 | '\\n'\n",
      "Step 12 | id=198 | '\\n'\n",
      "Step 11 | id=198 | '\\n'\n",
      "Step 12 | id=198 | '\\n'\n",
      "Step 13 | id=198 | '\\n'\n",
      "Step 14 | id=198 | '\\n'\n",
      "Step 15 | id=198 | '\\n'\n",
      "Step 13 | id=198 | '\\n'\n",
      "Step 14 | id=198 | '\\n'\n",
      "Step 15 | id=198 | '\\n'\n",
      "Step 16 | id=198 | '\\n'\n",
      "Step 17 | id=16744 | '文'\n",
      "Step 16 | id=198 | '\\n'\n",
      "Step 17 | id=16744 | '文'\n",
      "Step 18 | id=100146 | '的是'\n",
      "Step 19 | id=198 | '\\n'\n",
      "Step 18 | id=100146 | '的是'\n",
      "Step 19 | id=198 | '\\n'\n",
      "Step 20 | id=522 | '</'\n",
      "Step 21 | id=25 | ':'\n",
      "Step 20 | id=522 | '</'\n",
      "Step 21 | id=25 | ':'\n",
      "Step 22 | id=104689 | '不需要'\n",
      "Step 23 | id=198 | '\\n'\n",
      "Step 22 | id=104689 | '不需要'\n",
      "Step 23 | id=198 | '\\n'\n",
      "Step 24 | id=198 | '\\n'\n",
      "Step 25 | id=366 | ' <'\n",
      "Step 24 | id=198 | '\\n'\n",
      "Step 25 | id=366 | ' <'\n",
      "Step 26 | id=198 | '\\n'\n",
      "Step 27 | id=3837 | '，'\n",
      "Step 26 | id=198 | '\\n'\n",
      "Step 27 | id=3837 | '，'\n",
      "Step 28 | id=102104 | '回答'\n",
      "Step 29 | id=33108 | '和'\n",
      "Step 30 | id=198 | '\\n'\n",
      "Step 28 | id=102104 | '回答'\n",
      "Step 29 | id=33108 | '和'\n",
      "Step 30 | id=198 | '\\n'\n",
      "Step 31 | id=80443 | '没有'\n",
      "Step 32 | id=198 | '\\n'\n",
      "Step 33 | id=220 | ' '\n",
      "Step 31 | id=80443 | '没有'\n",
      "Step 32 | id=198 | '\\n'\n",
      "Step 33 | id=220 | ' '\n",
      "Step 34 | id=28319 | 'ี'\n",
      "Step 35 | id=198 | '\\n'\n",
      "Step 34 | id=28319 | 'ี'\n",
      "Step 35 | id=198 | '\\n'\n",
      "Step 36 | id=51461 | ' �'\n",
      "Step 37 | id=198 | '\\n'\n",
      "Step 38 | id=198 | '\\n'\n",
      "Step 36 | id=51461 | ' �'\n",
      "Step 37 | id=198 | '\\n'\n",
      "Step 38 | id=198 | '\\n'\n",
      "Step 39 | id=198 | '\\n'\n",
      "Step 40 | id=198 | '\\n'\n",
      "Step 39 | id=198 | '\\n'\n",
      "Step 40 | id=198 | '\\n'\n",
      "Step 41 | id=522 | '</'\n",
      "Step 42 | id=198 | '\\n'\n",
      "Step 43 | id=99165 | '很'\n",
      "Step 41 | id=522 | '</'\n",
      "Step 42 | id=198 | '\\n'\n",
      "Step 43 | id=99165 | '很'\n",
      "Step 44 | id=198 | '\\n'\n",
      "Step 45 | id=100154 | '作用'\n",
      "Step 44 | id=198 | '\\n'\n",
      "Step 45 | id=100154 | '作用'\n",
      "Step 46 | id=198 | '\\n'\n",
      "Step 47 | id=42140 | '多'\n",
      "Step 46 | id=198 | '\\n'\n",
      "Step 47 | id=42140 | '多'\n",
      "Step 48 | id=198 | '\\n'\n",
      "Step 49 | id=198 | '\\n'\n",
      "Step 48 | id=198 | '\\n'\n",
      "Step 49 | id=198 | '\\n'\n",
      "Step 50 | id=102406 | '表明'\n",
      "Step 51 | id=46944 | '一个'\n",
      "Step 50 | id=102406 | '表明'\n",
      "Step 51 | id=46944 | '一个'\n",
      "Step 52 | id=198 | '\\n'\n",
      "Step 53 | id=220 | ' '\n",
      "Step 52 | id=198 | '\\n'\n",
      "Step 53 | id=220 | ' '\n",
      "Step 54 | id=237 | '�'\n",
      "Step 55 | id=15946 | '中'\n",
      "Step 54 | id=237 | '�'\n",
      "Step 55 | id=15946 | '中'\n",
      "Step 56 | id=62244 | '如果'\n",
      "Step 57 | id=198 | '\\n'\n",
      "Step 56 | id=62244 | '如果'\n",
      "Step 57 | id=198 | '\\n'\n",
      "Step 58 | id=198 | '\\n'\n",
      "Step 59 | id=13 | '.'\n",
      "Step 58 | id=198 | '\\n'\n",
      "Step 59 | id=13 | '.'\n",
      "Step 60 | id=198 | '\\n'\n",
      "Step 61 | id=25 | ':'\n",
      "Step 60 | id=198 | '\\n'\n",
      "Step 61 | id=25 | ':'\n",
      "Step 62 | id=18947 | '个'\n",
      "Step 63 | id=47764 | '学'\n",
      "Step 62 | id=18947 | '个'\n",
      "Step 63 | id=47764 | '学'\n",
      "Step 64 | id=30534 | '要'\n",
      "Step 65 | id=46944 | '一个'\n",
      "Step 64 | id=30534 | '要'\n",
      "Step 65 | id=46944 | '一个'\n",
      "Step 66 | id=9370 | '的'\n",
      "Step 67 | id=30534 | '要'\n",
      "Step 66 | id=9370 | '的'\n",
      "Step 67 | id=30534 | '要'\n",
      "Step 68 | id=198 | '\\n'\n",
      "Step 69 | id=198 | '\\n'\n",
      "Step 68 | id=198 | '\\n'\n",
      "Step 69 | id=198 | '\\n'\n",
      "Step 70 | id=34187 | '了'\n",
      "Step 71 | id=30534 | '要'\n",
      "\n",
      "=== 提取到的查询 === []\n",
      "=== 去重后链接 ===\n",
      "(无)\n",
      "\n",
      "=== 模型输出片段 (原始前400) ===\n",
      "<think>\n",
      "重名\n",
      "近搜索、\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "文的是\n",
      "</:不需要\n",
      "\n",
      " <\n",
      "，回答和\n",
      "没有\n",
      " ี\n",
      " �\n",
      "\n",
      "\n",
      "\n",
      "</\n",
      "很\n",
      "作用\n",
      "多\n",
      "\n",
      "表明一个\n",
      " �中如果\n",
      "\n",
      ".\n",
      ":个学要一个的要\n",
      "\n",
      "了要\n",
      "\n",
      "==============================\n",
      "Step 70 | id=34187 | '了'\n",
      "Step 71 | id=30534 | '要'\n",
      "\n",
      "=== 提取到的查询 === []\n",
      "=== 去重后链接 ===\n",
      "(无)\n",
      "\n",
      "=== 模型输出片段 (原始前400) ===\n",
      "<think>\n",
      "重名\n",
      "近搜索、\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "文的是\n",
      "</:不需要\n",
      "\n",
      " <\n",
      "，回答和\n",
      "没有\n",
      " ี\n",
      " �\n",
      "\n",
      "\n",
      "\n",
      "</\n",
      "很\n",
      "作用\n",
      "多\n",
      "\n",
      "表明一个\n",
      " �中如果\n",
      "\n",
      ".\n",
      ":个学要一个的要\n",
      "\n",
      "了要\n",
      "\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "# 测试 3: 需要搜索的问题\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"测试 3: 需要搜索 - 明确使用 <search> 标签\")\n",
    "print(\"=\"*60)\n",
    "search_result = run_search_agent(\n",
    "    \"请帮我搜索: <search>Python 3.12 新特性</search>\",\n",
    "    max_steps=80,\n",
    "    verbose=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea1b13a",
   "metadata": {},
   "source": [
    "# 改进说明与下一步优化\n",
    "\n",
    "## 本次重构的关键修复:\n",
    "1. **修复生成逻辑** - 不再频繁清空 `generated` 列表,保留完整生成历史\n",
    "2. **多轮生成支持** - 搜索触发后启动新一轮生成,而非重置状态\n",
    "3. **改进终止条件** - 延迟搜索检测(至少5步后),避免过早触发\n",
    "4. **优化模板格式** - 改进 fallback chat 模板,提高兼容性\n",
    "5. **清理输出函数** - 移除特殊标记,保留可读内容\n",
    "\n",
    "## 下一步可以优化的内容:\n",
    "- **采样策略**: 使用 top-k / top-p / temperature 代替 argmax,增加多样性\n",
    "- **结构化工具调用**: 支持 JSON 格式 `<tool_call>{\"name\":\"search\",...}</tool_call>`\n",
    "- **多搜索源**: 聚合 Google/Bing/DuckDuckGo 等多个搜索引擎\n",
    "- **结果摘要**: 使用模型对搜索结果进行总结和相关性评分\n",
    "- **重试与限流**: 避免过频访问,添加指数退避\n",
    "- **对话缓存**: LRU / Redis 缓存历史对话和搜索结果\n",
    "- **安全过滤**: 域名白名单、恶意内容检测\n",
    "- **流式输出**: 实时显示生成的 token\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
