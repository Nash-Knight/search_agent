{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffd90379",
   "metadata": {},
   "source": [
    "Search Agent (Qwen3-0.6B) 重构版说明\n",
    "\n",
    "目标：基于本地 Qwen3-0.6B 搭建一个最小可用的搜索 Agent Pipeline。\n",
    "\n",
    "核心流程：\n",
    "1. 用户提供初始任务 prompt。\n",
    "2. 模型逐 token 生成并检测工具调用格式。\n",
    "3. 遇到搜索工具调用 => 执行搜索 => 将搜索结果注入上下文继续生成。\n",
    "4. 不再触发工具调用且出现终止标记（<eos> / eos token） => 输出最终链接集合。\n",
    "\n",
    "Notebook 结构：\n",
    "- 配置与依赖\n",
    "- 模型加载\n",
    "- 工具与解析层 (Tool / SearchTool / ToolCallParser)\n",
    "- AgentPipeline 主循环 (流式 + 工具接入)\n",
    "- 示例运行 (单函数入口)\n",
    "- 扩展建议\n",
    "\n",
    "约定：\n",
    "- 工具调用格式候选：`<tool_call:search>查询词` / `search: 查询词` / `[SEARCH] 查询词`\n",
    "- 工具响应结束 token id（暂用推测值）：151666 (</tool_response>)\n",
    "- 本示例仅做结构演示，未包含安全过滤、重试、并行优化。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e7c5d3",
   "metadata": {},
   "source": [
    "这一部分说明所需的依赖与环境前提，提醒读者检查本地模型目录 `./Qwen3-0.6B` 并在缺包时安装 `transformers`、`huggingface_hub`、`requests`、`beautifulsoup4`。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6574d46f",
   "metadata": {},
   "source": [
    "这个单元会动态检查依赖是否安装，并导入后续流程会用到的核心库；如果缺包会抛出清晰的提示便于补齐环境。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d6e7f154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 依赖检查与核心库导入\n",
    "import importlib\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Any\n",
    "\n",
    "REQUIRED_PACKAGES = [\n",
    "    (\"transformers\", \"transformers\"),\n",
    "    (\"torch\", \"torch\"),\n",
    "    (\"requests\", \"requests\"),\n",
    "    (\"beautifulsoup4\", \"bs4\"),\n",
    "]\n",
    "missing = []\n",
    "for pip_name, import_name in REQUIRED_PACKAGES:\n",
    "    try:\n",
    "        importlib.import_module(import_name)\n",
    "    except ModuleNotFoundError:\n",
    "        missing.append(pip_name)\n",
    "\n",
    "if missing:\n",
    "    raise ModuleNotFoundError(\n",
    "        \"缺失依赖: \" + \", \".join(missing) +\n",
    "        \"\\n请在当前环境中运行: pip install \" + \" \".join(missing)\n",
    "    )\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458670cb",
   "metadata": {},
   "source": [
    "下面的单元负责加载本地 Qwen3-0.6B 模型与分词器，并根据是否可用 GPU 自动选择 dtype 和 device_map。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6e55922a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载模型目录: Qwen3-0.6B\n",
      "模型加载完成，当前设备: cuda:0\n",
      "模型加载完成，当前设备: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# 模型与分词器加载\n",
    "MODEL_DIR = Path(\"Qwen3-0.6B\")\n",
    "if not MODEL_DIR.exists():\n",
    "    raise FileNotFoundError(f\"模型目录不存在: {MODEL_DIR.resolve()}\")\n",
    "\n",
    "print(f\"加载模型目录: {MODEL_DIR}\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(str(MODEL_DIR), local_files_only=True)\n",
    "\n",
    "dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "load_kwargs = {\"local_files_only\": True, \"torch_dtype\": dtype}\n",
    "if torch.cuda.is_available():\n",
    "    load_kwargs[\"device_map\"] = \"auto\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(str(MODEL_DIR), **load_kwargs)\n",
    "model.eval()\n",
    "print(\"模型加载完成，当前设备:\", model.device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54a2124",
   "metadata": {},
   "source": [
    "这一段用于快速检查 tokenizer 的特殊标记，以及检索包含 \"tool\" 关键词的 token 以辅助调试工具调用格式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8a72bc78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "特殊 token: {'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}\n",
      "其他特殊 token: ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']\n",
      "包含 'tool' 的 token 示例 (前 100):\n",
      "87183 toolbox\n",
      "44646 -tools\n",
      "66572 .toolStripButton\n",
      "15918 tools\n",
      "45714 /tools\n",
      "40224 -tool\n",
      "65894 Ġtoolkit\n",
      "78458 (toolbar\n",
      "25942 Ġtoolbar\n",
      "22785 _tool\n",
      "23154 .tools\n",
      "64448 .toolStripSeparator\n",
      "88265 .toolbox\n",
      "84904 .toolStripMenuItem\n",
      "151666 </tool_response>\n",
      "76265 _tooltip\n",
      "65695 _toolbar\n",
      "46902 ĠtoolStrip\n",
      "25451 Ġtooltip\n",
      "60646 -tooltip\n",
      "7375 Ġtools\n",
      "65539 toolStrip\n",
      "51281 uptools\n",
      "75027 /tool\n",
      "21268 .tool\n",
      "36316 ertools\n",
      "56466 Ġfunctools\n",
      "91234 Ġtooltips\n",
      "67870 Ġtoolbox\n",
      "63072 Ġstool\n",
      "48950 (tool\n",
      "5392 Ġtool\n",
      "151657 <tool_call>\n",
      "37530 toolbar\n",
      "63797 Ġsetuptools\n",
      "72790 -toolbar\n",
      "47416 .toolbar\n",
      "39723 _tools\n",
      "14172 tool\n",
      "67166 .tooltip\n",
      "89772 Ġstools\n",
      "24680 .toolStrip\n",
      "151658 </tool_call>\n",
      "41331 Ġitertools\n",
      "151665 <tool_response>\n",
      "21539 tooltip\n"
     ]
    }
   ],
   "source": [
    "# Tokenizer 信息检查\n",
    "print(\"特殊 token:\", tokenizer.special_tokens_map)\n",
    "print(\"其他特殊 token:\", tokenizer.additional_special_tokens)\n",
    "\n",
    "matched = []\n",
    "for token, tid in tokenizer.get_vocab().items():\n",
    "    if \"tool\" in token:\n",
    "        matched.append((tid, token))\n",
    "    if len(matched) >= 100:\n",
    "        break\n",
    "print(\"包含 'tool' 的 token 示例 (前 100):\")\n",
    "for tid, token in matched:\n",
    "    print(tid, token)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56094f88",
   "metadata": {},
   "source": [
    "后续工具实现依赖一些常量，这里集中定义工具结束 token、搜索模式、HTTP 头等基础配置，保持全局可见。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e2258de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 工具与解析层：基础配置\n",
    "TOOL_END_TOKEN_ID = 151666  # 推测为 </tool_response>\n",
    "SEARCH_PATTERNS = [\n",
    "    r\"search:\\s*(.*)\",       # 兼容旧格式 \"search: query\"\n",
    "    r\"\\[TOOL_CALL\\]\\s*\\n\\s*search:\\s*(.*)\", # 兼容旧多行格式\n",
    "    r\"<tool_call:search>(.*?)$\",  # 兼容旧XML样式\n",
    "    r\"\\[SEARCH\\]\\s+(.*)$\",      # 兼容旧标签\n",
    "]\n",
    "# 主要使用 <search>...</search> 新标签；旧模式保留以便混合 prompt 测试\n",
    "HEADERS = {\"User-Agent\": \"Mozilla/5.0 (SearchAgent Prototype)\"}\n",
    "MAX_LINKS_DEFAULT = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de732ac6",
   "metadata": {},
   "source": [
    "紧接着的代码定义抽象工具基类和抓取 jina.ai 搜索结果的 `SearchTool`，并处理异常返回结构化信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c2d93d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 工具实现：SearchTool\n",
    "class Tool:\n",
    "    name: str\n",
    "\n",
    "    def run(self, *args, **kwargs) -> Dict[str, Any]:\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "class SearchTool(Tool):\n",
    "    name = \"search\"\n",
    "\n",
    "    def run(self, query: str, max_links: int = MAX_LINKS_DEFAULT) -> Dict[str, Any]:\n",
    "        url = f\"https://www.jina.ai/search?q={requests.utils.quote(query)}\"\n",
    "        try:\n",
    "            resp = requests.get(url, headers=HEADERS, timeout=15)\n",
    "            resp.raise_for_status()\n",
    "        except Exception as exc:\n",
    "            return {\"query\": query, \"links\": [], \"error\": str(exc)}\n",
    "\n",
    "        soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "        links: List[str] = []\n",
    "        for anchor in soup.select(\"a[href]\"):\n",
    "            href = anchor.get(\"href\")\n",
    "            if href and href.startswith(\"http\") and \"jina.ai\" not in href:\n",
    "                links.append(href)\n",
    "            if len(links) >= max_links:\n",
    "                break\n",
    "        return {\"query\": query, \"links\": links}\n",
    "\n",
    "\n",
    "search_tool = SearchTool()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0fbac1",
   "metadata": {},
   "source": [
    "为了抽取模型输出中的工具调用，这里实现 `ToolCallParser`，兼容简单正则与预留的 JSON 包装格式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b4244c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 工具调用解析器\n",
    "class ToolCallParser:\n",
    "    def find_search(self, text: str):\n",
    "        for pattern in SEARCH_PATTERNS:\n",
    "            match = re.search(pattern, text, re.IGNORECASE)\n",
    "            if match:\n",
    "                query = match.group(1).strip()\n",
    "                query = re.split(r\"</tool_response>|<eos>|\\n\", query)[0].strip()\n",
    "                if query:\n",
    "                    return query\n",
    "        return None\n",
    "\n",
    "    def find_json_tool(self, text: str):\n",
    "        # 预留 JSON 工具调用格式: <tool_call>{\"name\":\"search\", ...}</tool_call>\n",
    "        match = re.search(r\"<tool_call>\\s*(\\{.*?\\})\\s*</tool_call>\", text, re.DOTALL)\n",
    "        if not match:\n",
    "            return None\n",
    "        raw_json = match.group(1)\n",
    "        try:\n",
    "            import json\n",
    "            return json.loads(raw_json)\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "\n",
    "parser = ToolCallParser()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1259774",
   "metadata": {},
   "source": [
    "在进入主循环前，需要一个统一的对话模板封装，这样模型在没有原生 chat 模板时也能 fallback 到简单的 role:content 拼接。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c0f852b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chat 模板包装\n",
    "def apply_chat_template(messages):\n",
    "    if hasattr(tokenizer, \"apply_chat_template\"):\n",
    "        try:\n",
    "            return tokenizer.apply_chat_template(\n",
    "                messages,\n",
    "                tokenize=False,\n",
    "                add_generation_prompt=True,\n",
    "            )\n",
    "        except Exception:\n",
    "            pass\n",
    "    lines = [f\"{m['role']}: {m['content']}\" for m in messages]\n",
    "    lines.append(\"assistant:\")\n",
    "    return \"\\n\".join(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8136e26",
   "metadata": {},
   "source": [
    "接下来的 Pipeline 单元负责逐 token 流式生成、检测工具调用、执行搜索并把结果拼回消息列表，是整个 Agent 的核心逻辑。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbdc868",
   "metadata": {},
   "source": [
    "系统提示（System Prompt）\n",
    "\n",
    "下面新增一个系统级指导信息，要求模型在需要检索时使用形如 <search>关键词</search> 的标签包围搜索词。生成过程中一旦形成闭合标签即触发搜索，将搜索结果与原始关键词回注入上下文继续回答。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "961308ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 系统提示定义\n",
    "GLOBAL_SYSTEM_PROMPT = (\n",
    "    \"你是一个搜索增强助手。判断需要外部信息时，请生成 <search>关键词</search> 标签。\"\n",
    "    \" 标签内只放原始搜索关键词，避免多句。形成 </search> 闭合后会自动检索 Jina.ai。\"\n",
    "    \" 系统会将检索到的若干链接与原始关键词回传，你需要利用这些结果综合回答。\"\n",
    "    \" 如果不需要搜索就直接正常回答并结束。不要虚构搜索结果。\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "35b1efb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AgentPipeline 定义\n",
    "@dataclass\n",
    "class GenerationResult:\n",
    "    final_text: str\n",
    "    search_queries: List[str]\n",
    "    links: List[str]\n",
    "\n",
    "\n",
    "class AgentPipeline:\n",
    "    def __init__(self, model, tokenizer, tool: Tool, parser: ToolCallParser):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.tool = tool\n",
    "        self.parser = parser\n",
    "\n",
    "    def _prepare_inputs(self, messages: List[Dict[str, str]]):\n",
    "        prompt = apply_chat_template(messages)\n",
    "        if verbose_g: # 使用全局变量来控制打印\n",
    "            print(\"--- PROMPT START ---\")\n",
    "            print(prompt)\n",
    "            print(\"--- PROMPT END ---\\n\")\n",
    "        encoded = self.tokenizer([prompt], return_tensors=\"pt\")\n",
    "        return (\n",
    "            encoded[\"input_ids\"].to(self.model.device),\n",
    "            encoded[\"attention_mask\"].to(self.model.device),\n",
    "        )\n",
    "\n",
    "    def _append_message(self, messages: List[Dict[str, str]], role: str, content: str):\n",
    "        messages.append({\"role\": role, \"content\": content})\n",
    "\n",
    "    def _dedup(self, items: List[str]) -> List[str]:\n",
    "        seen = set()\n",
    "        ordered = []\n",
    "        for item in items:\n",
    "            if item not in seen:\n",
    "                seen.add(item)\n",
    "                ordered.append(item)\n",
    "        return ordered\n",
    "\n",
    "    def stream(self, messages: List[Dict[str, str]], *, max_steps: int = 96, verbose: bool = True) -> GenerationResult:\n",
    "        global verbose_g\n",
    "        verbose_g = verbose\n",
    "        \n",
    "        input_ids, attention_mask = self._prepare_inputs(messages)\n",
    "        generated: List[int] = []\n",
    "        cache = None\n",
    "        collected_links: List[str] = []\n",
    "        search_queries: List[str] = []\n",
    "        processed_search_segments: List[str] = []  # 已处理的<search>内容，防重复\n",
    "\n",
    "        with torch.inference_mode():\n",
    "            for step in range(max_steps):\n",
    "                outputs = self.model(\n",
    "                    input_ids=input_ids,\n",
    "                    attention_mask=attention_mask,\n",
    "                    use_cache=True,\n",
    "                    past_key_values=cache,\n",
    "                )\n",
    "                logits = outputs.logits[:, -1, :]\n",
    "                cache = outputs.past_key_values\n",
    "\n",
    "                next_token = torch.argmax(logits, dim=-1)\n",
    "                token_id = next_token.item()\n",
    "                generated.append(token_id)\n",
    "\n",
    "                # 续写输入\n",
    "                input_ids = torch.cat([input_ids, next_token.unsqueeze(0)], dim=1)\n",
    "                attention_mask = torch.cat([\n",
    "                    attention_mask,\n",
    "                    torch.ones_like(next_token).unsqueeze(0),\n",
    "                ], dim=1)\n",
    "\n",
    "                token_text = self.tokenizer.decode([token_id], skip_special_tokens=False)\n",
    "                full_text = self.tokenizer.decode(generated, skip_special_tokens=False)\n",
    "                if verbose:\n",
    "                    print(f\"Step {step:02d} | id={token_id} | {repr(token_text)}\")\n",
    "\n",
    "                # 终止条件\n",
    "                if token_id == self.tokenizer.eos_token_id or \"<eos>\" in full_text:\n",
    "                    if verbose:\n",
    "                        print(\"[终止] 遇到 EOS 标记，停止生成。\")\n",
    "                    break\n",
    "\n",
    "                # 旧格式兼容：正则/JSON 检测\n",
    "                json_call = self.parser.find_json_tool(full_text)\n",
    "                if json_call and isinstance(json_call, dict):\n",
    "                    name = json_call.get(\"name\")\n",
    "                    args = json_call.get(\"args\", {})\n",
    "                    if verbose:\n",
    "                        print(f\"\\n[JSON 工具触发] name={name} args={args}\")\n",
    "                    if name == self.tool.name and \"query\" in args:\n",
    "                        query = args[\"query\"]\n",
    "                        search_queries.append(query)\n",
    "                        result = self.tool.run(query)\n",
    "                        links = result.get(\"links\", [])\n",
    "                        collected_links.extend(links)\n",
    "                        feedback = \"搜索结果:\\n\" + \"\\n\".join(links or [\"(无结果)\"])\n",
    "                        self._append_message(messages, \"assistant\", full_text)\n",
    "                        self._append_message(messages, \"user\", f\"关键词: {query}\\n\" + feedback + \"\\n请继续整合。\")\n",
    "                        input_ids, attention_mask = self._prepare_inputs(messages)\n",
    "                        generated.clear()\n",
    "                        cache = None\n",
    "                        continue\n",
    "\n",
    "                # 兼容旧正则 search: / [SEARCH]\n",
    "                legacy_query = self.parser.find_search(full_text)\n",
    "                if legacy_query and legacy_query not in processed_search_segments:\n",
    "                    if verbose:\n",
    "                        print(f\"\\n[搜索触发(旧格式)] query={legacy_query}\")\n",
    "                    processed_search_segments.append(legacy_query)\n",
    "                    search_queries.append(legacy_query)\n",
    "                    result = self.tool.run(legacy_query)\n",
    "                    links = result.get(\"links\", [])\n",
    "                    collected_links.extend(links)\n",
    "                    feedback = \"搜索结果:\\n\" + \"\\n\".join(links or [\"(无结果)\"])\n",
    "                    self._append_message(messages, \"assistant\", full_text)\n",
    "                    self._append_message(messages, \"user\", f\"关键词: {legacy_query}\\n\" + feedback + \"\\n请继续整合。\")\n",
    "                    input_ids, attention_mask = self._prepare_inputs(messages)\n",
    "                    generated.clear()\n",
    "                    cache = None\n",
    "                    continue\n",
    "\n",
    "                # 新格式：<search>...</search>\n",
    "                # 查找所有闭合标签\n",
    "                search_matches = re.findall(r\"<search>(.*?)</search>\", full_text, flags=re.DOTALL)\n",
    "                for match in search_matches:\n",
    "                    cleaned_query = match.strip().replace(\"\\n\", \" \")\n",
    "                    if cleaned_query and cleaned_query not in processed_search_segments:\n",
    "                        if verbose:\n",
    "                            print(f\"\\n[搜索触发(<search>标签)] query={cleaned_query}\")\n",
    "                        processed_search_segments.append(cleaned_query)\n",
    "                        search_queries.append(cleaned_query)\n",
    "                        result = self.tool.run(cleaned_query)\n",
    "                        links = result.get(\"links\", [])\n",
    "                        collected_links.extend(links)\n",
    "                        feedback = \"搜索结果:\\n\" + \"\\n\".join(links or [\"(无结果)\"])\n",
    "                        # 将当前生成内容作为assistant消息，再追加用户反馈用于下一轮生成\n",
    "                        self._append_message(messages, \"assistant\", full_text)\n",
    "                        self._append_message(\n",
    "                            messages,\n",
    "                            \"user\",\n",
    "                            f\"关键词: {cleaned_query}\\n\" + feedback + \"\\n请结合结果继续回答。\"\n",
    "                        )\n",
    "                        input_ids, attention_mask = self._prepare_inputs(messages)\n",
    "                        generated.clear()\n",
    "                        cache = None\n",
    "                        break  # 本步只处理一个新触发，重新编码后继续循环\n",
    "\n",
    "        final_text = self.tokenizer.decode(generated, skip_special_tokens=False)\n",
    "        return GenerationResult(\n",
    "            final_text=final_text,\n",
    "            search_queries=search_queries,\n",
    "            links=self._dedup(collected_links),\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a519b92a",
   "metadata": {},
   "source": [
    "为了方便外部调用，下面会构造 `run_search_agent` 包装函数，复用已经初始化好的 Pipeline 并打印关键信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bb5cd870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 统一入口函数\n",
    "pipeline = AgentPipeline(model=model, tokenizer=tokenizer, tool=search_tool, parser=parser)\n",
    "\n",
    "# 全局变量用于跨单元输出 SUMMARY\n",
    "global_last_query = None\n",
    "global_last_cleaned = None\n",
    "\n",
    "def _clean_assistant_output(raw: str) -> str:\n",
    "    import re\n",
    "    cleaned = re.sub(r'<think>.*?</think>', '', raw, flags=re.DOTALL)\n",
    "    cleaned = cleaned.replace('<|im_end|>', '').replace('<eos>', '')\n",
    "    cleaned = re.sub(r'\\n{3,}', '\\n\\n', cleaned).strip()\n",
    "    cleaned = cleaned.replace('</think>', '')\n",
    "    return cleaned\n",
    "\n",
    "def run_search_agent(query: str, *, max_steps: int = 72, verbose: bool = True) -> GenerationResult:\n",
    "    global global_last_query, global_last_cleaned\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": GLOBAL_SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": query},\n",
    "    ]\n",
    "    result = pipeline.stream(messages, max_steps=max_steps, verbose=verbose)\n",
    "    raw_final = result.final_text\n",
    "    assistant_output = _clean_assistant_output(raw_final)\n",
    "\n",
    "    # 保留旧格式块\n",
    "    print(\"\\n=== 提取到的查询 ===\", result.search_queries)\n",
    "    print(\"=== 去重后链接 ===\")\n",
    "    if result.links:\n",
    "        for i,l in enumerate(result.links,1):\n",
    "            print(i,l)\n",
    "    else:\n",
    "        print(\"(无)\")\n",
    "    print(\"\\n=== 模型输出片段 (原始前400) ===\")\n",
    "    print(raw_final[:400])\n",
    "    print(\"\\n==============================\")\n",
    "\n",
    "    global_last_query = query\n",
    "    global_last_cleaned = assistant_output if assistant_output else '(空)'\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb27e7f0",
   "metadata": {},
   "source": [
    "最后的示例单元提供一个默认 prompt，方便手动触发一次搜索调用进行调试；默认注释掉实际调用以免误运行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ff058712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running Simple Query ---\n",
      "--- PROMPT START ---\n",
      "<|im_start|>system\n",
      "你是一个搜索增强助手。判断需要外部信息时，请生成 <search>关键词</search> 标签。 标签内只放原始搜索关键词，避免多句。形成 </search> 闭合后会自动检索 Jina.ai。 系统会将检索到的若干链接与原始关键词回传，你需要利用这些结果综合回答。 如果不需要搜索就直接正常回答并结束。不要虚构搜索结果。<|im_end|>\n",
      "<|im_start|>user\n",
      "hello<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n",
      "--- PROMPT END ---\n",
      "\n",
      "Step 00 | id=151667 | '<think>'\n",
      "Step 01 | id=198 | '\\n'\n",
      "Step 02 | id=23811 | ' hello'\n",
      "Step 01 | id=198 | '\\n'\n",
      "Step 02 | id=23811 | ' hello'\n",
      "Step 03 | id=27641 | '密'\n",
      "Step 04 | id=58143 | ' 和'\n",
      "Step 03 | id=27641 | '密'\n",
      "Step 04 | id=58143 | ' 和'\n",
      "Step 05 | id=198 | '\\n'\n",
      "Step 06 | id=151668 | '</think>'\n",
      "Step 05 | id=198 | '\\n'\n",
      "Step 06 | id=151668 | '</think>'\n",
      "Step 07 | id=46306 | '完'\n",
      "Step 08 | id=105470 | '相关的'\n",
      "Step 07 | id=46306 | '完'\n",
      "Step 08 | id=105470 | '相关的'\n",
      "Step 09 | id=18947 | '个'\n",
      "Step 10 | id=16744 | '文'\n",
      "Step 09 | id=18947 | '个'\n",
      "Step 10 | id=16744 | '文'\n",
      "Step 11 | id=14224 | '件'\n",
      "Step 12 | id=104689 | '不需要'\n",
      "Step 11 | id=14224 | '件'\n",
      "Step 12 | id=104689 | '不需要'\n",
      "Step 13 | id=99689 | '词'\n",
      "Step 14 | id=198 | '\\n'\n",
      "Step 15 | id=62244 | '如果'\n",
      "Step 13 | id=99689 | '词'\n",
      "Step 14 | id=198 | '\\n'\n",
      "Step 15 | id=62244 | '如果'\n",
      "Step 16 | id=3837 | '，'\n",
      "Step 17 | id=198 | '\\n'\n",
      "Step 16 | id=3837 | '，'\n",
      "Step 17 | id=198 | '\\n'\n",
      "Step 18 | id=198 | '\\n'\n",
      "Step 19 | id=198 | '\\n'\n",
      "Step 20 | id=3837 | '，'\n",
      "Step 18 | id=198 | '\\n'\n",
      "Step 19 | id=198 | '\\n'\n",
      "Step 20 | id=3837 | '，'\n",
      "Step 21 | id=198 | '\\n'\n",
      "Step 22 | id=20412 | '是'\n",
      "Step 21 | id=198 | '\\n'\n",
      "Step 22 | id=20412 | '是'\n",
      "Step 23 | id=102104 | '回答'\n",
      "Step 24 | id=102104 | '回答'\n",
      "Step 23 | id=102104 | '回答'\n",
      "Step 24 | id=102104 | '回答'\n",
      "Step 25 | id=100158 | '一下'\n",
      "Step 26 | id=220 | ' '\n",
      "Step 25 | id=100158 | '一下'\n",
      "Step 26 | id=220 | ' '\n",
      "Step 27 | id=198 | '\\n'\n",
      "Step 28 | id=271 | '\\n\\n'\n",
      "Step 27 | id=198 | '\\n'\n",
      "Step 28 | id=271 | '\\n\\n'\n",
      "Step 29 | id=31382 | 'ال'\n",
      "Step 30 | id=34204 | '于'\n",
      "Step 29 | id=31382 | 'ال'\n",
      "Step 30 | id=34204 | '于'\n",
      "Step 31 | id=198 | '\\n'\n",
      "Step 32 | id=271 | '\\n\\n'\n",
      "Step 33 | id=198 | '\\n'\n",
      "Step 31 | id=198 | '\\n'\n",
      "Step 32 | id=271 | '\\n\\n'\n",
      "Step 33 | id=198 | '\\n'\n",
      "Step 34 | id=16 | '1'\n",
      "Step 35 | id=30543 | '️'\n",
      "Step 34 | id=16 | '1'\n",
      "Step 35 | id=30543 | '️'\n",
      "Step 36 | id=198 | '\\n'\n",
      "Step 37 | id=220 | ' '\n",
      "Step 38 | id=220 | ' '\n",
      "Step 36 | id=198 | '\\n'\n",
      "Step 37 | id=220 | ' '\n",
      "Step 38 | id=220 | ' '\n",
      "Step 39 | id=28319 | 'ี'\n",
      "Step 40 | id=198 | '\\n'\n",
      "Step 39 | id=28319 | 'ี'\n",
      "Step 40 | id=198 | '\\n'\n",
      "Step 41 | id=1773 | '。'\n",
      "Step 42 | id=35946 | '我'\n",
      "Step 41 | id=1773 | '。'\n",
      "Step 42 | id=35946 | '我'\n",
      "Step 43 | id=18947 | '个'\n",
      "Step 44 | id=30918 | '求'\n",
      "Step 43 | id=18947 | '个'\n",
      "Step 44 | id=30918 | '求'\n",
      "Step 45 | id=49434 | ' �'\n",
      "Step 46 | id=31382 | 'ال'\n",
      "Step 45 | id=49434 | ' �'\n",
      "Step 46 | id=31382 | 'ال'\n",
      "Step 47 | id=13935 | '·'\n",
      "Step 48 | id=198 | '\\n'\n",
      "Step 49 | id=111436 | '问答'\n",
      "Step 47 | id=13935 | '·'\n",
      "Step 48 | id=198 | '\\n'\n",
      "Step 49 | id=111436 | '问答'\n",
      "Step 50 | id=198 | '\\n'\n",
      "Step 51 | id=13 | '.'\n",
      "Step 52 | id=198 | '\\n'\n",
      "Step 50 | id=198 | '\\n'\n",
      "Step 51 | id=13 | '.'\n",
      "Step 52 | id=198 | '\\n'\n",
      "Step 53 | id=59151 | '结果'\n",
      "Step 54 | id=42140 | '多'\n",
      "Step 53 | id=59151 | '结果'\n",
      "Step 54 | id=42140 | '多'\n",
      "Step 55 | id=18158 | '取'\n",
      "Step 56 | id=198 | '\\n'\n",
      "Step 55 | id=18158 | '取'\n",
      "Step 56 | id=198 | '\\n'\n",
      "Step 57 | id=220 | ' '\n",
      "Step 58 | id=220 | ' '\n",
      "Step 57 | id=220 | ' '\n",
      "Step 58 | id=220 | ' '\n",
      "Step 59 | id=105966 | '原始'\n",
      "Step 60 | id=151645 | '<|im_end|>'\n",
      "[终止] 遇到 EOS 标记，停止生成。\n",
      "\n",
      "=== 提取到的查询 === []\n",
      "=== 去重后链接 ===\n",
      "(无)\n",
      "\n",
      "=== 模型输出片段 (原始前400) ===\n",
      "<think>\n",
      " hello密 和\n",
      "</think>完相关的个文件不需要词\n",
      "如果，\n",
      "\n",
      "\n",
      "，\n",
      "是回答回答一下 \n",
      "\n",
      "\n",
      "ال于\n",
      "\n",
      "\n",
      "\n",
      "1️\n",
      "  ี\n",
      "。我个求 �ال·\n",
      "问答\n",
      ".\n",
      "结果多取\n",
      "  原始<|im_end|>\n",
      "\n",
      "==============================\n",
      "\n",
      "==============================\n",
      "\n",
      "Step 59 | id=105966 | '原始'\n",
      "Step 60 | id=151645 | '<|im_end|>'\n",
      "[终止] 遇到 EOS 标记，停止生成。\n",
      "\n",
      "=== 提取到的查询 === []\n",
      "=== 去重后链接 ===\n",
      "(无)\n",
      "\n",
      "=== 模型输出片段 (原始前400) ===\n",
      "<think>\n",
      " hello密 和\n",
      "</think>完相关的个文件不需要词\n",
      "如果，\n",
      "\n",
      "\n",
      "，\n",
      "是回答回答一下 \n",
      "\n",
      "\n",
      "ال于\n",
      "\n",
      "\n",
      "\n",
      "1️\n",
      "  ี\n",
      "。我个求 �ال·\n",
      "问答\n",
      ".\n",
      "结果多取\n",
      "  原始<|im_end|>\n",
      "\n",
      "==============================\n",
      "\n",
      "==============================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 示例调用 1: 简单查询\n",
    "simple_query = \"hello\"\n",
    "print(\"--- Running Simple Query ---\")\n",
    "simple_result = run_search_agent(simple_query, verbose=True)\n",
    "print(\"\\n\" + \"=\"*30 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e5e598",
   "metadata": {},
   "source": [
    "简单 query 的输入输出总结"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4c86462c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUMMARY\n",
      "\n",
      "query:hello\n",
      "\n",
      "response:完相关的个文件不需要词\n",
      "如果，\n",
      "\n",
      "，\n",
      "是回答回答一下 \n",
      "\n",
      "ال于\n",
      "\n",
      "1️\n",
      "  ี\n",
      "。我个求 �ال·\n",
      "问答\n",
      ".\n",
      "结果多取\n",
      "  原始\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SUMMARY 输出（简单查询）\n",
    "print(\"SUMMARY\\n\")\n",
    "print(f\"query:{simple_query}\\n\")\n",
    "print(f\"response:{_clean_assistant_output(simple_result.final_text) if simple_result else '(空)'}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bf6eaaa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running Complex Query ---\n",
      "--- PROMPT START ---\n",
      "<|im_start|>system\n",
      "你是一个搜索增强助手。判断需要外部信息时，请生成 <search>关键词</search> 标签。 标签内只放原始搜索关键词，避免多句。形成 </search> 闭合后会自动检索 Jina.ai。 系统会将检索到的若干链接与原始关键词回传，你需要利用这些结果综合回答。 如果不需要搜索就直接正常回答并结束。不要虚构搜索结果。<|im_end|>\n",
      "<|im_start|>user\n",
      "给我一些近期开源中文多模态项目。\n",
      "<search>开源 中文 多模态 项目</search><|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n",
      "--- PROMPT END ---\n",
      "\n",
      "Step 00 | id=151667 | '<think>'\n",
      "Step 01 | id=198 | '\\n'\n",
      "Step 02 | id=29258 | '重'\n",
      "Step 01 | id=198 | '\\n'\n",
      "Step 02 | id=29258 | '重'\n",
      "Step 03 | id=13072 | '名'\n",
      "Step 04 | id=198 | '\\n'\n",
      "Step 03 | id=13072 | '名'\n",
      "Step 04 | id=198 | '\\n'\n",
      "Step 05 | id=59258 | '近'\n",
      "Step 06 | id=78973 | '搜索'\n",
      "Step 05 | id=59258 | '近'\n",
      "Step 06 | id=78973 | '搜索'\n",
      "Step 07 | id=5373 | '、'\n",
      "Step 08 | id=198 | '\\n'\n",
      "Step 07 | id=5373 | '、'\n",
      "Step 08 | id=198 | '\\n'\n",
      "Step 09 | id=198 | '\\n'\n",
      "Step 10 | id=198 | '\\n'\n",
      "Step 09 | id=198 | '\\n'\n",
      "Step 10 | id=198 | '\\n'\n",
      "Step 11 | id=198 | '\\n'\n",
      "Step 12 | id=198 | '\\n'\n",
      "Step 11 | id=198 | '\\n'\n",
      "Step 12 | id=198 | '\\n'\n",
      "Step 13 | id=198 | '\\n'\n",
      "Step 14 | id=198 | '\\n'\n",
      "Step 15 | id=198 | '\\n'\n",
      "Step 13 | id=198 | '\\n'\n",
      "Step 14 | id=198 | '\\n'\n",
      "Step 15 | id=198 | '\\n'\n",
      "Step 16 | id=198 | '\\n'\n",
      "Step 17 | id=16744 | '文'\n",
      "Step 16 | id=198 | '\\n'\n",
      "Step 17 | id=16744 | '文'\n",
      "Step 18 | id=100146 | '的是'\n",
      "Step 19 | id=198 | '\\n'\n",
      "Step 18 | id=100146 | '的是'\n",
      "Step 19 | id=198 | '\\n'\n",
      "Step 20 | id=522 | '</'\n",
      "Step 21 | id=25 | ':'\n",
      "Step 20 | id=522 | '</'\n",
      "Step 21 | id=25 | ':'\n",
      "Step 22 | id=104689 | '不需要'\n",
      "Step 23 | id=198 | '\\n'\n",
      "Step 22 | id=104689 | '不需要'\n",
      "Step 23 | id=198 | '\\n'\n",
      "Step 24 | id=198 | '\\n'\n",
      "Step 25 | id=366 | ' <'\n",
      "Step 24 | id=198 | '\\n'\n",
      "Step 25 | id=366 | ' <'\n",
      "Step 26 | id=198 | '\\n'\n",
      "Step 27 | id=3837 | '，'\n",
      "Step 26 | id=198 | '\\n'\n",
      "Step 27 | id=3837 | '，'\n",
      "Step 28 | id=102104 | '回答'\n",
      "Step 29 | id=33108 | '和'\n",
      "Step 30 | id=198 | '\\n'\n",
      "Step 28 | id=102104 | '回答'\n",
      "Step 29 | id=33108 | '和'\n",
      "Step 30 | id=198 | '\\n'\n",
      "Step 31 | id=80443 | '没有'\n",
      "Step 32 | id=198 | '\\n'\n",
      "Step 33 | id=220 | ' '\n",
      "Step 31 | id=80443 | '没有'\n",
      "Step 32 | id=198 | '\\n'\n",
      "Step 33 | id=220 | ' '\n",
      "Step 34 | id=28319 | 'ี'\n",
      "Step 35 | id=198 | '\\n'\n",
      "Step 34 | id=28319 | 'ี'\n",
      "Step 35 | id=198 | '\\n'\n",
      "Step 36 | id=51461 | ' �'\n",
      "Step 37 | id=198 | '\\n'\n",
      "Step 38 | id=198 | '\\n'\n",
      "Step 36 | id=51461 | ' �'\n",
      "Step 37 | id=198 | '\\n'\n",
      "Step 38 | id=198 | '\\n'\n",
      "Step 39 | id=198 | '\\n'\n",
      "Step 40 | id=198 | '\\n'\n",
      "Step 39 | id=198 | '\\n'\n",
      "Step 40 | id=198 | '\\n'\n",
      "Step 41 | id=522 | '</'\n",
      "Step 42 | id=198 | '\\n'\n",
      "Step 43 | id=99165 | '很'\n",
      "Step 41 | id=522 | '</'\n",
      "Step 42 | id=198 | '\\n'\n",
      "Step 43 | id=99165 | '很'\n",
      "Step 44 | id=198 | '\\n'\n",
      "Step 45 | id=100154 | '作用'\n",
      "Step 44 | id=198 | '\\n'\n",
      "Step 45 | id=100154 | '作用'\n",
      "Step 46 | id=198 | '\\n'\n",
      "Step 47 | id=42140 | '多'\n",
      "Step 46 | id=198 | '\\n'\n",
      "Step 47 | id=42140 | '多'\n",
      "Step 48 | id=198 | '\\n'\n",
      "Step 49 | id=198 | '\\n'\n",
      "Step 48 | id=198 | '\\n'\n",
      "Step 49 | id=198 | '\\n'\n",
      "Step 50 | id=102406 | '表明'\n",
      "Step 51 | id=46944 | '一个'\n",
      "Step 50 | id=102406 | '表明'\n",
      "Step 51 | id=46944 | '一个'\n",
      "Step 52 | id=198 | '\\n'\n",
      "Step 53 | id=220 | ' '\n",
      "Step 52 | id=198 | '\\n'\n",
      "Step 53 | id=220 | ' '\n",
      "Step 54 | id=237 | '�'\n",
      "Step 55 | id=15946 | '中'\n",
      "Step 54 | id=237 | '�'\n",
      "Step 55 | id=15946 | '中'\n",
      "Step 56 | id=62244 | '如果'\n",
      "Step 57 | id=198 | '\\n'\n",
      "Step 56 | id=62244 | '如果'\n",
      "Step 57 | id=198 | '\\n'\n",
      "Step 58 | id=198 | '\\n'\n",
      "Step 59 | id=13 | '.'\n",
      "Step 58 | id=198 | '\\n'\n",
      "Step 59 | id=13 | '.'\n",
      "Step 60 | id=198 | '\\n'\n",
      "Step 61 | id=25 | ':'\n",
      "Step 60 | id=198 | '\\n'\n",
      "Step 61 | id=25 | ':'\n",
      "Step 62 | id=18947 | '个'\n",
      "Step 63 | id=47764 | '学'\n",
      "Step 62 | id=18947 | '个'\n",
      "Step 63 | id=47764 | '学'\n",
      "Step 64 | id=30534 | '要'\n",
      "Step 65 | id=46944 | '一个'\n",
      "Step 64 | id=30534 | '要'\n",
      "Step 65 | id=46944 | '一个'\n",
      "Step 66 | id=9370 | '的'\n",
      "Step 67 | id=30534 | '要'\n",
      "Step 66 | id=9370 | '的'\n",
      "Step 67 | id=30534 | '要'\n",
      "Step 68 | id=198 | '\\n'\n",
      "Step 69 | id=198 | '\\n'\n",
      "Step 68 | id=198 | '\\n'\n",
      "Step 69 | id=198 | '\\n'\n",
      "Step 70 | id=34187 | '了'\n",
      "Step 71 | id=30534 | '要'\n",
      "\n",
      "=== 提取到的查询 === []\n",
      "=== 去重后链接 ===\n",
      "(无)\n",
      "\n",
      "=== 模型输出片段 (原始前400) ===\n",
      "<think>\n",
      "重名\n",
      "近搜索、\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "文的是\n",
      "</:不需要\n",
      "\n",
      " <\n",
      "，回答和\n",
      "没有\n",
      " ี\n",
      " �\n",
      "\n",
      "\n",
      "\n",
      "</\n",
      "很\n",
      "作用\n",
      "多\n",
      "\n",
      "表明一个\n",
      " �中如果\n",
      "\n",
      ".\n",
      ":个学要一个的要\n",
      "\n",
      "了要\n",
      "\n",
      "==============================\n",
      "Step 70 | id=34187 | '了'\n",
      "Step 71 | id=30534 | '要'\n",
      "\n",
      "=== 提取到的查询 === []\n",
      "=== 去重后链接 ===\n",
      "(无)\n",
      "\n",
      "=== 模型输出片段 (原始前400) ===\n",
      "<think>\n",
      "重名\n",
      "近搜索、\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "文的是\n",
      "</:不需要\n",
      "\n",
      " <\n",
      "，回答和\n",
      "没有\n",
      " ี\n",
      " �\n",
      "\n",
      "\n",
      "\n",
      "</\n",
      "很\n",
      "作用\n",
      "多\n",
      "\n",
      "表明一个\n",
      " �中如果\n",
      "\n",
      ".\n",
      ":个学要一个的要\n",
      "\n",
      "了要\n",
      "\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "# 示例调用 2: 复杂查询 (带<search>标签演示)\n",
    "complex_query = \"\"\"\n",
    "给我一些近期开源中文多模态项目。\n",
    "<search>开源 中文 多模态 项目</search>\n",
    "\"\"\".strip()\n",
    "print(\"--- Running Complex Query ---\")\n",
    "complex_result = run_search_agent(complex_query, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf60178a",
   "metadata": {},
   "source": [
    "复杂 query 的输入输出总结"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9ab38fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUMMARY\n",
      "\n",
      "query:给我一些近期开源中文多模态项目。\n",
      "<search>开源 中文 多模态 项目</search>\n",
      "\n",
      "response:<think>\n",
      "重名\n",
      "近搜索、\n",
      "\n",
      "文的是\n",
      "</:不需要\n",
      "\n",
      " <\n",
      "，回答和\n",
      "没有\n",
      " ี\n",
      " �\n",
      "\n",
      "</\n",
      "很\n",
      "作用\n",
      "多\n",
      "\n",
      "表明一个\n",
      " �中如果\n",
      "\n",
      ".\n",
      ":个学要一个的要\n",
      "\n",
      "了要\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SUMMARY 输出（复杂查询）\n",
    "print(\"SUMMARY\\n\")\n",
    "print(f\"query:{complex_query}\\n\")\n",
    "print(f\"response:{_clean_assistant_output(complex_result.final_text) if complex_result else '(空)'}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea1b13a",
   "metadata": {},
   "source": [
    "# 下一步可以优化的内容\n",
    "- 结构化 JSON 工具调用：`<tool_call>{\"name\":\"search\",\"args\":{\"query\":\"...\"}}</tool_call>`\n",
    "- 重试与速率限制，避免过频访问\n",
    "- 多搜索源聚合与去重合并\n",
    "- 搜索结果摘要与相关性评分\n",
    "- 采样策略：top-k / nucleus 代替 argmax\n",
    "- 对话与搜索缓存（LRU / SQLite）\n",
    "- 域名白名单 / 恶意内容过滤"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
